---
title: 关于gpt的一些想法和可能的应用
permalink: /docs/zh/about-gpt
key: docs-zh-about-gpt
mermaid: true
---
<style>
.flowchart-link{stroke: green !important;}
#flowchart-pointEnd {fill: green !important;stroke: green !important;}
text.actor > tspan {fill: green !important;font-size: 16px !important;font-weight:bold !important;}
#arrowhead path {fill: green !important;}   
.messageText {fill: green !important;font-size: 16px !important;font-weight:bold !important;}
.messageLine0 {stroke: green !important;}
.messageLine1 {stroke: green !important;}
.relation {stroke: green !important;stroke-width: 2 !important;}
th {
	background: #dddddd;
	word-wrap: break-word;
	text-align: center;
}
tr:nth-child(odd) {   
  background-color: #c0e1ff;
  color: #222; 
}
tr:nth-child(even) {
  background-color: #fef6de;
  color: #222;
}
</style>

本章节是蹭热点，大体打算谈谈关于这一波AI的发展趋势，及其与Eight哲学上的共通之处。最后再谈论一下其发展展望及可能的运用。

### 语言与共识

GPT原理上是一个文字推理引擎，通过海量的文本处理和统计，得到了基于文字进行概率反馈的能力。之所以最近引起关注，还是因为它的能力引起了一系列戏剧性的效果，在某种意义上超乎想象，显得非常神奇。人们在觉得不可思议的同时，并不明白为何如此，以致于对其的未来展望和发展方向感觉困惑不解。

若要深入触及GPT能力的实质，就需要探讨语言的本质。这是一个漫长的论述，也并不适合在本专题中展开，但在此可以给出一个简单的定义：语言是人类对于经验形成共识的表述。在这个层面上，GPT的基本原理与Eight一致。

回忆一下[第一章](common-sense)这张关于经验主义形成共识的图，GPT的奥秘就在这里：

![共识](/eight/assets/images/common-sense.gif){:.rounded width="720px" style="display:block; margin-left:auto; margin-right:auto"}

根据晚期维特根斯坦的认识，语言本身是经验性的，是约定俗成的，受环境、对象、背景等一系列因素影响，注定了其意义边界的模糊与不确定，不能准确的表达无二义的固有概念，也就不能作为推导出绝对真理的工具——那无异于缘木求鱼。当然，晚期维特根斯坦在《哲学研究》中还提出很多有趣的概念，诸如`家族相似性`{:.info}，想研究语言为何在近似的背景下显示出相似的意义，在不同的环境下却显示出不同含义。但显然维特根斯坦最终没能找到问题的根本。

其实这个问题并不困难，看我们上面那张图，如果将里面任意一个common sense（cs），用一个词表达，这就是这个词的本质——词的本质在于它并无本质，它的意义随使用者的经验而存在。所以语言的问题，并不在它本身，而在于它的使用者，在于人身上。`语言本质上是人对经验共性的表达`{:.success}。

如果每一个人经验不同，同一个词对他的含义就不同，所表达的内容就不同。语言在不同的人之间传递思想，依靠的就是人与人之间通过共同或类似的经验获得的共识，无论这些经验是来自人类的亲身体验还是通过语言传播和思想实验学习而得。所以，思维处于不同层次的人，很难做到思想的有效沟通，即便他们准确的用词表达。

更深一步，不同人之间的经验交集，不仅决定了语言的含义，也决定了语言的信息密度。如果存在高度共识的群体，例如家庭背景、成长环境、教育程度、人生道路相似的群体，他们的经验交集就越大，显然拥有更多`共同的经验`{:.success}，也就拥有更多`共同的语言`{:.success}。他们彼此沟通自然顺畅得多，同一个词表达的共同含义就更为丰富。

更有甚者，一对长期朝夕相处的夫妇，经历太多共同的经验和记忆，它们之间交流沟通的词句信息密度更非寻常人际交往可比。可能一句话、一个词、甚至一个眼神、一个表情都能够传达足够的信息，让彼此明白对方所思所想。从某种意义上讲，语言并不怎么特殊，也并非传递信息和思想的唯一方式（相类似的还有手语），尽管它是最普遍的方式——那不过是它最为容易实现罢了。

所以，`语言怎么可能会有明确固定的含义呢？`{:.error}

回过头来再看看，所谓家族相似性以及随之而来的语言无本质也就顺利成章了——语言的意义既然蕴含在人和人之间的共同经验中，那么显然不同的人使用同一词会有不同含义。某个人A与B交流时使用game这个词，自然会跟与C交流时使用同一个词含义不同。但这两种场景下，词的含义又有相似之处。那是因为不仅该词的含义使用了同一个A的经验，而且B和C关于game的经验也有交集。但随着D、E、F、G、H、I的加入，这个词的含义逐渐走样了，因为他们的经验交集不断在变形，尽管每次变形都有共同之处`（家族相似）`{:.info}。

![家族相似性](/eight/assets/images/family.png){:.rounded width="720px" style="display:block; margin-left:auto; margin-right:auto"}

看看上图，在维特根斯坦的`语言游戏`{:.info}中，Game这个词，在不同经验的个体中传播时所表达内容的含义并不相同，甚至不同的意义相去甚远。这就是`家族相似性`{:.info}，这就是为什么语言本质上是没有`（确定的）`{:.error}意义的。

维特根斯坦在哲学史上是一个独特的存在，他的独特在于他是一张白纸，研究哲学而对哲学一无所知。这样的好处是他没有历史负担，不受经验干扰，能产生纯粹的思想，而坏处是不能触类旁通，明白自己思想的意义和位置。

如果他能抛开研究语言本身，从古典哲学的认识论角度去思考，他就应该明白，从早期的《逻辑哲学论》到晚期《哲学研究》，其实走的是一条从理性主义迈向经验主义的道路，正如他生长在奥地利却又在三一学院求学一样。德国是理性主义的沃土，而英伦则是经验主义的摇篮。以致于他前后思想是如此的相互冲突。

当然这并不怪他，这是整个时代的错误。哲学在20世纪的语言学转向其实是一场悲剧，某种程度上是人类妥协退缩的结果。在20世纪上半叶经历过两次世界大战，然后是长期的冷战的阵营割据，无论是从民众本身，还是从政治需要上，都不再希望出现革新的思想、叛逆的世界观和方法论。这导致哲学从本体论、认识论等重大问题中退出，从研究世界和人类社会的基本规律中退出，专注于语言这一狭小领域。但这是令人遗憾的，就如前面所述——语言不过是经验的公式化表达，想依靠研究语言去研究世界的本质也不过是本末倒置，一叶障目。

### GPT与共识

以上关于语言与经验的讨论，已经在逐渐接近GPT的真相。GPT究竟是什么？为何能够与人类进行沟通？又为何跟人类存在不同？

如果语言是经验的表达，对于人类来说，经验来源于经历与记忆。那对于GPT来说，这经验又是什么？这个问题绝大多数人能够回答——文本语料。

GPT之所以能够与人类以相似的方式交流，在于它采用了与人类相似的经验系统——多层神经网络。它经验的来源就是文本——静态的语言。它之所以能够与人进行沟通，在于它通过海量的文本学习，而文本又记录了经验事实，从而获得了语言的共识，这些共识与人的经验构成了交集。
这也能解释为何GPT往往会要求提供一些背景信息（如：假设你是一个新闻记者之类）来加强交流效果，那是提高经验共识的方式，与上面介绍的语言在相似背景人员之间的意义密度增强异曲同工。当然，对于GPT而言，这等同于缩小采样范围，提升概率密度。

人类的经验，其实是个统计系统。人类是从过往经验中概率较高的`事实`{:.error}，`推理`{:.info}出即将发生的`事实`{:.error}，这个从客观事实输入大脑，到基于经验概率反馈的过程，叫做`思考`{:.error}，而语言则是思考的形式化表达。经验主义的本质，就在于归纳客观事实。

GPT的处理流程与这个过程相当相似，所以GPT看起来很像拥有了人类的思维。但接触多了，就能发现GPT存在明显不同。

实际上，GPT的`思考`{:.error}方式与人类是有很大区别的，主要在以下几个方面：
- 人类的`思维`{:.error}并不仅仅借助于经验归纳这一单一系统（尽管这是最主要的），除此之外还有演绎推理（理性主义）系统，还受情感系统、价值取向系统等诸多因素干扰；
- 人类经验存储的是`事实`{:.error}，而GPT存储的是`词语`{:.error}，这也意味着人类推理的是`事实`{:.error}，而GPT推理的是`词语`{:.error}。词语也许能够表达事实，也许不能，但词语推理的结果，一定是看似通顺的意思；
- GPT只处理文本，并且是一个通识系统。意味着它虽与人类具备经验共识，但却只是来源于书本，同时，它虽博览群书，但却缺乏与特别的个体交流的特殊经验。就像我在前面所说，人与人的联系是在人与人相处过程中存在的，不同的个体之间联系必然不同。基于通识的GPT，缺乏与人建立联系的能力，所以它的语言缺乏人的样貌。

实际上，目前GPT的训练方式其天花板不太可能太高，尤其是当互联网上的文本泛滥着GPT自己制造出来的东西之后。

最后说个有意思的事。人工智能的发展，跟语言哲学算是休戚与共。早期的人工智能，走的是理性主义道路，研究谓词逻辑和演绎推理，所谓的`符号主义`{:.error}。而后有转向了神经网络，也即所谓的`连接主义`{:.error}，从此就与演绎推理无关，讲究经验积累（数据训练）和概率统计了。某种意义上，它的命运跟维特根斯坦很像，都是理性主义走投无路之后走向充满未知和不明所以的经验主义。

### GPT的展望

GPT在未来要走向实用化和专业化，泛用型训练显然是不会成功的。并且用文本训练本身就是误入歧途，按这个路子下去，GPT无法改变胡说八道的根性，更无法提供真知灼见。这不符合`认识的客观规律`{:.error}。

但GPT毕竟证明了多层神经网络模拟经验系统的有效性，关键在于这个经验输入到底是什么。

长期以来，人们使用互联网仅仅只是互联网的一小部分，就是所谓的`静态互联网`{:.error}，主体是由互联网上遗存的文本构成。未来互联网信息将会丰富太多，各种物理设备（所谓物联网）发生的数据（如智能手表记录人的运动量，每日行走步数，呼吸，心率等等），各种可以被观测和捕捉的行为和事件（如记录互联网页面的点击事件），将共同构成互联网的`动态`{:.error}部分。这些数据的数据量比静态文本大得多，而内容也丰富得多。
但很长时间里，这些数据都被丢弃掉了。主要原因是人们不知道应该如何利用这些数据，而这数据量也太大了，以致于不太方便存储。

GPT的神经网络给我们一个很好的方法——用来利用和存储这些流式数据。将其作为训练输入，丢弃掉数据本身，存留下经验参数。这与人类大脑的记忆系统相似，记忆系统也是丢弃掉经历的细节，存留下有效的经验。

所以，未来的GPT发展方向不应该还是训练文本，而是像人类一样，面向流式事件，记忆`客观事实`{:.success}。这才是符合认识论的`仿生`{:.info}。唯有这样的路径，GPT才能在掌握大量事实之后，概率推理出符合客观实际的结论，改掉它满嘴胡言乱语的习惯。

当然，这个过程并不容易，至少还有客观事实到抽象概念的归纳，抽象概念到语言文字的映射等几个重要环节。

另一方面，GPT不仅应记忆通识，还应该与它的服务对象`共同生活`{:.success}:smiley:，以获得与伙伴的共同经验和共识，深刻理解对方，这样才能对对方提出深刻的见解而不是随意敷衍。例如，服务于一个公司的GPT，就应该把公司各个方面发生的事件、如人员、财务、生产、管理等输入其记忆系统（神经网络），而服务于家庭和个人的GPT，则应该不断记录家庭成员与个人的方方面面，包括起床时间、餐饮习惯、工作节奏、娱乐爱好。这些不是以文字输入，而是通过感知系统和物联网进行数据采集后输入`发生的事实`{:.error}。

也许在未来，最了解你的人不再是你的伴侣，而是一套神经网络的经验参数。你的一颦一笑，一个皱眉，这些参数都能知道你在想什么，并且为你提供帮助。

从另一方面来说，未来的通用共识GPT也必然被私有化部署的GPT所取代，或许每个人都有属于他自己的`知己`{:.success}，一套几百G或几百T的记忆参数:smirk:。

### GPT与Eight

GPT看起来跟Eight完全是两个不同东西，但其背后的哲学原理是一致的——基于经验主义的共识体系。只是应用方式全然不同：

- GPT是基于经验概率，习得与人之间的共识交集，从而组织语言与人进行交流与沟通；
- Eight则是在已知相似经历的人存在大量共识的前提下，通过约束语言（谓词，Eight的所有15个接口14个方法都是谓词）来限定表达方式，从而使相似的共识得到相似的表达，以使组件`（事实的表达）`{:.success}能够互通。

除此之外，Eight是很适合做流式事件采集的喔:wink:

![Eight&GPT](/eight/assets/images/eight-gpt.png){:.rounded width="720px" style="display:block; margin-left:auto; margin-right:auto"}